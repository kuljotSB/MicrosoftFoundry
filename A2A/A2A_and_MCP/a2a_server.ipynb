{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c34603c",
   "metadata": {},
   "source": [
    "## A2A and MCP Server Setup with Microsoft Foundry Agents - Streaming Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddf6bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install a2a-sdk==0.3.8 azure-ai-projects==2.0.0b2 python-dotenv azure-identity uvicorn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ef5b2",
   "metadata": {},
   "source": [
    "### Setting Up the Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b3dffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "load_dotenv()\n",
    "\n",
    "foundry_project_endpoint = os.getenv(\"FOUNDRY_PROJECT_ENDPOINT\")\n",
    "model_deployment_name = os.getenv(\"MODEL_DEPLOYMENT_NAME\")\n",
    "mcp_server_name = os.getenv(\"MCP_SERVER_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321ef870",
   "metadata": {},
   "source": [
    "### Setting up the Foundry Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e13c4504",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client = AIProjectClient(\n",
    "    endpoint=foundry_project_endpoint,\n",
    "    credential=DefaultAzureCredential(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c93ec6d",
   "metadata": {},
   "source": [
    "### Getting the MCP Server Connection ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e00f7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MCP Server Connection ID is: /subscriptions/d7b3870f-56a8-4d3b-8e6d-2464d0148f29/resourceGroups/carbonops-dev-rg/providers/Microsoft.CognitiveServices/accounts/carbonopsdevai4434735199/projects/demo-proj/connections/MicrosoftLearn\n"
     ]
    }
   ],
   "source": [
    "connection_id = \"\"\n",
    "\n",
    "async for connection in project_client.connections.list():\n",
    "    if connection.name == mcp_server_name:\n",
    "        connection_id = connection.id\n",
    "        break\n",
    "\n",
    "print(f\"The MCP Server Connection ID is: {connection_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ee4e33",
   "metadata": {},
   "source": [
    "### Creating the MCP Tool Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d96a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import MCPTool, Tool\n",
    "\n",
    "tool = MCPTool(\n",
    "    server_label = \"microsoft_learn_server\",\n",
    "    server_url=\"https://learn.microsoft.com/api/mcp\",\n",
    "    require_approval=\"never\",\n",
    "    project_connection_id=connection_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fe07ad",
   "metadata": {},
   "source": [
    "### Creating the Agent that will be used in A2A Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30bf758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created (id: A2A-MCP-Agent:1, name: A2A-MCP-Agent, version: 1)\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects.models import PromptAgentDefinition\n",
    "\n",
    "agent_name = \"A2A-MCP-Agent\"\n",
    "\n",
    "agent = await project_client.agents.create_version(\n",
    "    agent_name=agent_name,\n",
    "    definition=PromptAgentDefinition(\n",
    "        model=model_deployment_name,\n",
    "        instructions=\"You are an intelligent assistant that can interact with the Microsoft Learn MCP server to provide users with relevant learning resources and information about Microsoft technologies.\",\n",
    "        tools = [tool]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# printing the agent id\n",
    "print(f\"Agent created (id: {agent.id}, name: {agent.name}, version: {agent.version})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def58deb",
   "metadata": {},
   "source": [
    "### Creating the Foundry Agent Class with Function Executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "915f722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoundryAgent():\n",
    "    \"\"\"This class will contain helper functions for interacting with our Foundry Agent\"\"\"\n",
    "\n",
    "    async def invoke_agent_stream(self, user_query: str):\n",
    "        try: \n",
    "            openai_client = project_client.get_openai_client()\n",
    "\n",
    "            conversation = await openai_client.conversations.create()\n",
    "\n",
    "            response_stream_events = await openai_client.responses.create(\n",
    "                conversation=conversation.id,\n",
    "                extra_body = {\n",
    "                    \"agent\": {\n",
    "                        \"name\": agent.name,\n",
    "                        \"type\": \"agent_reference\"\n",
    "                    }\n",
    "                },\n",
    "                input = user_query,\n",
    "                stream = True\n",
    "            )\n",
    "            async for event in response_stream_events:\n",
    "                if event.type == \"response.output_text.delta\":\n",
    "                        yield {'content': event.delta, 'done': False}\n",
    "            yield {'content': '', 'done': True}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'errorï¼š{e!s}')\n",
    "            yield {\n",
    "                'content': 'Sorry, an error occurred while processing your request.',\n",
    "                'done': True,\n",
    "            }\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c321ac4b",
   "metadata": {},
   "source": [
    "### Creating the A2A Agent Executor with Streaming Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "676bdbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2a.server.agent_execution import AgentExecutor, RequestContext\n",
    "from a2a.server.events import EventQueue\n",
    "from a2a.utils import new_agent_text_message\n",
    "from a2a.types import (\n",
    "    TaskArtifactUpdateEvent,\n",
    "    TaskState,\n",
    "    TaskStatus,\n",
    "    TaskStatusUpdateEvent,\n",
    ")\n",
    "from a2a.utils import new_text_artifact\n",
    "\n",
    "\n",
    "class FoundryAgentExecutor(AgentExecutor):\n",
    "    \"\"\"Foundry Agent Executor Definition.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.agent = FoundryAgent()\n",
    "\n",
    "    async def execute(\n",
    "        self,\n",
    "        context: RequestContext,\n",
    "        event_queue: EventQueue,\n",
    "    ) -> None:\n",
    "        query = context.get_user_input()\n",
    "        if not context.message:\n",
    "            raise Exception('No message provided')\n",
    "\n",
    "        # If your agent does not support streaming, just call invoke_agent\n",
    "        async for event in self.agent.invoke_agent_stream(query):\n",
    "            message = TaskArtifactUpdateEvent(\n",
    "                context_id=context.context_id,  # type: ignore\n",
    "                task_id=context.task_id,  # type: ignore\n",
    "                artifact=new_text_artifact(\n",
    "                    name='current_result',\n",
    "                    text=event['content'],\n",
    "                ),\n",
    "            )\n",
    "            await event_queue.enqueue_event(message)\n",
    "            if event['done']:\n",
    "                break\n",
    "\n",
    "        status = TaskStatusUpdateEvent(\n",
    "            context_id=context.context_id,  # type: ignore\n",
    "            task_id=context.task_id,  # type: ignore\n",
    "            status=TaskStatus(state=TaskState.completed),\n",
    "            final=True,\n",
    "        )\n",
    "        await event_queue.enqueue_event(status)\n",
    "\n",
    "    async def cancel(\n",
    "        self, context: RequestContext, event_queue: EventQueue\n",
    "    ) -> None:\n",
    "        raise Exception('cancel not supported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eeafcc",
   "metadata": {},
   "source": [
    "### Creating the Agent Skill Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92f1db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2a.types import (\n",
    "    AgentCapabilities,\n",
    "    AgentCard,\n",
    "    AgentSkill,\n",
    ")\n",
    "\n",
    "skill = AgentSkill(\n",
    "    id = \"mcp_a2a_foundry_agent_skill\",\n",
    "    name = \"This skill interacts with Microsoft Foundry via MCP Server\",\n",
    "    description = \"This skill allows the agent to interact with Microsoft Foundry using the MCP Server connection to provide users with relevant learning resources and information about Microsoft technologies.\",\n",
    "    tags = [\"mcp a2a foundry agent\"],\n",
    "    examples = [\"Give me code to interact with Microsoft Foundry using the Python SDK.\", \"How to provision an azure storage account using the Azure CLI?\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5257695",
   "metadata": {},
   "source": [
    "### Creating the Agent Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2f66e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_agent_card = AgentCard(\n",
    "    name = \"A2A MCP Foundry Demo Agent\",\n",
    "    description = \"Foundry Demo Agent to Show A2A Usage with Microsoft Foundry and MCP Server\",\n",
    "    url = \"http://localhost:8080\",\n",
    "    version = \"1.0.0\",\n",
    "    default_input_modes=['text'],\n",
    "    default_output_modes=['text'],\n",
    "    capabilities=AgentCapabilities(streaming=True),\n",
    "    skills = [skill]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d11fd2",
   "metadata": {},
   "source": [
    "### Creating the Request Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "298209c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2a.server.request_handlers import DefaultRequestHandler\n",
    "from a2a.server.tasks import InMemoryTaskStore\n",
    "\n",
    "request_handler = DefaultRequestHandler(\n",
    "    agent_executor = FoundryAgentExecutor(),\n",
    "    task_store = InMemoryTaskStore()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7909ad9",
   "metadata": {},
   "source": [
    "### Creating the A2A Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a20cd1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2a.server.apps import A2AStarletteApplication\n",
    "\n",
    "server = A2AStarletteApplication(\n",
    "    agent_card = public_agent_card,\n",
    "    http_handler = request_handler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96ab2dc",
   "metadata": {},
   "source": [
    "### Starting the A2A Server\n",
    "\n",
    "Navigate to http://localhost:8080/.well-known/agent.json to see the agent public card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30a9c20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [34676]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:64912 - \"GET /.well-known/agent-card.json HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64912 - \"POST / HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [34676]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import uvicorn\n",
    "uvicorn.run(server.build(), host=\"0.0.0.0\", port=8080)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
