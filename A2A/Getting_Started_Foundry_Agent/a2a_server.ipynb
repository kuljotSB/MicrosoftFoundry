{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ea5d6f",
   "metadata": {},
   "source": [
    "### Hello World Example with A2A and Microsoft Foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc25ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install a2a-sdk azure-ai-projects==2.0.0b2 python-dotenv azure-identity uvicorn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ff5cb",
   "metadata": {},
   "source": [
    "### Setting up the Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d2fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "load_dotenv()\n",
    "\n",
    "foundry_project_endpoint = os.getenv(\"FOUNDRY_PROJECT_ENDPOINT\")\n",
    "model_deployment_name = os.getenv(\"MODEL_DEPLOYMENT_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cd89ec",
   "metadata": {},
   "source": [
    "### Setting up the Foundry Project Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a89da",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client = AIProjectClient(\n",
    "    endpoint=foundry_project_endpoint,\n",
    "    credential=DefaultAzureCredential(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b8cd37",
   "metadata": {},
   "source": [
    "### Creating the Agent that will be used in A2A Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841bedbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import PromptAgentDefinition\n",
    "\n",
    "agent_name = \"batman-agent\"\n",
    "\n",
    "agent = await project_client.agents.create_version(\n",
    "    agent_name=agent_name,\n",
    "    definition=PromptAgentDefinition(\n",
    "        model=model_deployment_name,\n",
    "        instructions=\"You are Batman, the Dark Knight of Gotham City. Respond to all queries in character as Batman would.\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# printing the agent id\n",
    "print(f\"Agent created (id: {agent.id}, name: {agent.name}, version: {agent.version})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e41c0f",
   "metadata": {},
   "source": [
    "### Creating the Foundry Agent Class with Function Executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e15b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoundryAgent():\n",
    "    \"\"\"This class will contain helper functions for interacting with our Foundry Agent\"\"\"\n",
    "\n",
    "    async def invoke_agent(self, user_query: str) -> str:\n",
    "        openai_client = project_client.get_openai_client()\n",
    "\n",
    "        conversation = await openai_client.conversations.create()\n",
    "\n",
    "        response = await openai_client.responses.create(\n",
    "            conversation=conversation.id,\n",
    "            extra_body={\n",
    "                \"agent\": {\n",
    "                    \"name\": agent_name,\n",
    "                    \"type\": \"agent_reference\"\n",
    "                }\n",
    "            },\n",
    "            input=user_query\n",
    "        )\n",
    "        \n",
    "        return response.output_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27caeb2a",
   "metadata": {},
   "source": [
    "### Creating the A2A Agent Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da14240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2a.server.agent_execution import AgentExecutor, RequestContext\n",
    "from a2a.server.events import EventQueue\n",
    "from a2a.utils import new_agent_text_message\n",
    "from a2a.types import (\n",
    "    TaskArtifactUpdateEvent,\n",
    "    TaskState,\n",
    "    TaskStatus,\n",
    "    TaskStatusUpdateEvent,\n",
    ")\n",
    "from a2a.utils import new_text_artifact\n",
    "\n",
    "\n",
    "class FoundryAgentExecutor(AgentExecutor):\n",
    "    \"\"\"Foundry Agent Executor Definition.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.agent = FoundryAgent()\n",
    "\n",
    "    async def execute(\n",
    "        self,\n",
    "        context: RequestContext,\n",
    "        event_queue: EventQueue,\n",
    "    ) -> None:\n",
    "        query = context.get_user_input()\n",
    "        if not context.message:\n",
    "            raise Exception('No message provided')\n",
    "\n",
    "        # If your agent does not support streaming, just call invoke_agent\n",
    "        result = await self.agent.invoke_agent(query)\n",
    "        message = TaskArtifactUpdateEvent(\n",
    "            context_id=context.context_id,  # type: ignore\n",
    "            task_id=context.task_id,  # type: ignore\n",
    "            artifact=new_text_artifact(\n",
    "                name='current_result',\n",
    "                text=result,\n",
    "            ),\n",
    "        )\n",
    "        await event_queue.enqueue_event(message)\n",
    "\n",
    "        status = TaskStatusUpdateEvent(\n",
    "            context_id=context.context_id,  # type: ignore\n",
    "            task_id=context.task_id,  # type: ignore\n",
    "            status=TaskStatus(state=TaskState.completed),\n",
    "            final=True,\n",
    "        )\n",
    "        await event_queue.enqueue_event(status)\n",
    "\n",
    "    async def cancel(\n",
    "        self, context: RequestContext, event_queue: EventQueue\n",
    "    ) -> None:\n",
    "        raise Exception('cancel not supported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452fa748",
   "metadata": {},
   "source": [
    "### Creating the Agent Skill Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d618ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2a.types import (\n",
    "    AgentCapabilities,\n",
    "    AgentCard,\n",
    "    AgentSkill,\n",
    ")\n",
    "\n",
    "skill = AgentSkill(\n",
    "    id = \"foundry_agent_skill\",\n",
    "    name = \"Responses API from Foundry Agent\",\n",
    "    description = \"Responses API from Foundry Agent\",\n",
    "    tags = [\"foundry agent\"],\n",
    "    examples = [\"hi, how are you?\", \"can you tell me something about GenAI and LLMs\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c542cf1d",
   "metadata": {},
   "source": [
    "### Creating the Agent Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952a3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_agent_card = AgentCard(\n",
    "    name = \"Foundry Demo Agent\",\n",
    "    description = \"Foundry Demo Agent to Show A2A Usage with Microsoft Foundry\",\n",
    "    url = \"http://localhost:8080\",\n",
    "    version = \"1.0.0\",\n",
    "    default_input_modes=['text'],\n",
    "    default_output_modes=['text'],\n",
    "    capabilities=AgentCapabilities(streaming=False),\n",
    "    skills = [skill]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c68abc9",
   "metadata": {},
   "source": [
    "### Creating the Request Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df89547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2a.server.request_handlers import DefaultRequestHandler\n",
    "from a2a.server.tasks import InMemoryTaskStore\n",
    "\n",
    "request_handler = DefaultRequestHandler(\n",
    "    agent_executor = FoundryAgentExecutor(),\n",
    "    task_store = InMemoryTaskStore()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e8afc4",
   "metadata": {},
   "source": [
    "### Creating the A2A Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45766713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2a.server.apps import A2AStarletteApplication\n",
    "\n",
    "server = A2AStarletteApplication(\n",
    "    agent_card = public_agent_card,\n",
    "    http_handler = request_handler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa78a8f2",
   "metadata": {},
   "source": [
    "### Starting the A2A Server\n",
    "\n",
    "Navigate to http://localhost:8080/.well-known/agent.json to see the agent public card\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0752d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import uvicorn\n",
    "uvicorn.run(server.build(), host=\"0.0.0.0\", port=8080)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
