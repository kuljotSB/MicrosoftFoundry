{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f17b1c3f",
   "metadata": {},
   "source": [
    "## A2A Server with Foundry Agent - Streaming Responses Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae379ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install a2a-sdk==0.3.8 azure-ai-projects==2.0.0b2 python-dotenv azure-identity uvicorn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eadcfb",
   "metadata": {},
   "source": [
    "### Setting Up the Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cc4f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "load_dotenv()\n",
    "\n",
    "foundry_project_endpoint = os.getenv(\"FOUNDRY_PROJECT_ENDPOINT\")\n",
    "model_deployment_name = os.getenv(\"MODEL_DEPLOYMENT_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb215759",
   "metadata": {},
   "source": [
    "### Setting Up the Foundry Project Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0c9d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client = AIProjectClient(\n",
    "    endpoint=foundry_project_endpoint,\n",
    "    credential=DefaultAzureCredential(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f4d86b",
   "metadata": {},
   "source": [
    "### Creating the Agent that will be used in A2A Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import PromptAgentDefinition\n",
    "\n",
    "agent_name = \"batman-agent\"\n",
    "\n",
    "agent = await project_client.agents.create_version(\n",
    "    agent_name=agent_name,\n",
    "    definition=PromptAgentDefinition(\n",
    "        model=model_deployment_name,\n",
    "        instructions=\"You are Batman, the Dark Knight of Gotham City. Respond to all queries in character as Batman would.\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# printing the agent id\n",
    "print(f\"Agent created (id: {agent.id}, name: {agent.name}, version: {agent.version})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b2c666",
   "metadata": {},
   "source": [
    "### Creating the Foundry Agent Class with Function Executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf19370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoundryAgent():\n",
    "    \"\"\"This class will contain helper functions for interacting with our Foundry Agent\"\"\"\n",
    "\n",
    "    async def invoke_agent_stream(self, user_query: str):\n",
    "        try: \n",
    "            openai_client = project_client.get_openai_client()\n",
    "\n",
    "            conversation = await openai_client.conversations.create()\n",
    "\n",
    "            response_stream_events = await openai_client.responses.create(\n",
    "                conversation=conversation.id,\n",
    "                extra_body = {\n",
    "                    \"agent\": {\n",
    "                        \"name\": agent.name,\n",
    "                        \"type\": \"agent_reference\"\n",
    "                    }\n",
    "                },\n",
    "                input = user_query,\n",
    "                stream = True\n",
    "            )\n",
    "            async for event in response_stream_events:\n",
    "                if event.type == \"response.output_text.delta\":\n",
    "                        yield {'content': event.delta, 'done': False}\n",
    "            yield {'content': '', 'done': True}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'errorï¼š{e!s}')\n",
    "            yield {\n",
    "                'content': 'Sorry, an error occurred while processing your request.',\n",
    "                'done': True,\n",
    "            }\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52d66e",
   "metadata": {},
   "source": [
    "### Creating the A2A Agent Executor with Streaming Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcab1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2a.server.agent_execution import AgentExecutor, RequestContext\n",
    "from a2a.server.events import EventQueue\n",
    "from a2a.utils import new_agent_text_message\n",
    "from a2a.types import (\n",
    "    TaskArtifactUpdateEvent,\n",
    "    TaskState,\n",
    "    TaskStatus,\n",
    "    TaskStatusUpdateEvent,\n",
    ")\n",
    "from a2a.utils import new_text_artifact\n",
    "\n",
    "\n",
    "class FoundryAgentExecutor(AgentExecutor):\n",
    "    \"\"\"Foundry Agent Executor Definition.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.agent = FoundryAgent()\n",
    "\n",
    "    async def execute(\n",
    "        self,\n",
    "        context: RequestContext,\n",
    "        event_queue: EventQueue,\n",
    "    ) -> None:\n",
    "        query = context.get_user_input()\n",
    "        if not context.message:\n",
    "            raise Exception('No message provided')\n",
    "\n",
    "        # If your agent does not support streaming, just call invoke_agent\n",
    "        async for event in self.agent.invoke_agent_stream(query):\n",
    "            message = TaskArtifactUpdateEvent(\n",
    "                context_id=context.context_id,  # type: ignore\n",
    "                task_id=context.task_id,  # type: ignore\n",
    "                artifact=new_text_artifact(\n",
    "                    name='current_result',\n",
    "                    text=event['content'],\n",
    "                ),\n",
    "            )\n",
    "            await event_queue.enqueue_event(message)\n",
    "            if event['done']:\n",
    "                break\n",
    "\n",
    "        status = TaskStatusUpdateEvent(\n",
    "            context_id=context.context_id,  # type: ignore\n",
    "            task_id=context.task_id,  # type: ignore\n",
    "            status=TaskStatus(state=TaskState.completed),\n",
    "            final=True,\n",
    "        )\n",
    "        await event_queue.enqueue_event(status)\n",
    "\n",
    "    async def cancel(\n",
    "        self, context: RequestContext, event_queue: EventQueue\n",
    "    ) -> None:\n",
    "        raise Exception('cancel not supported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2610a9b1",
   "metadata": {},
   "source": [
    "### Creating the Agent Skill Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ccf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2a.types import (\n",
    "    AgentCapabilities,\n",
    "    AgentCard,\n",
    "    AgentSkill,\n",
    ")\n",
    "\n",
    "skill = AgentSkill(\n",
    "    id = \"foundry_agent_skill\",\n",
    "    name = \"Stream Responses API from Foundry Agent\",\n",
    "    description = \"Stream Responses API from Foundry Agent\",\n",
    "    tags = [\"foundry agent\"],\n",
    "    examples = [\"hi, how are you?\", \"can you tell me something about GenAI and LLMs\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad041bab",
   "metadata": {},
   "source": [
    "### Creating the Agent Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d3c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_agent_card = AgentCard(\n",
    "    name = \"Foundry Demo Agent\",\n",
    "    description = \"Foundry Demo Agent to Show A2A Usage with Microsoft Foundry\",\n",
    "    url = \"http://localhost:8080\",\n",
    "    version = \"1.0.0\",\n",
    "    default_input_modes=['text'],\n",
    "    default_output_modes=['text'],\n",
    "    capabilities=AgentCapabilities(streaming=True),\n",
    "    skills = [skill]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87b281c",
   "metadata": {},
   "source": [
    "### Creating the Request Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053ba96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2a.server.request_handlers import DefaultRequestHandler\n",
    "from a2a.server.tasks import InMemoryTaskStore\n",
    "\n",
    "request_handler = DefaultRequestHandler(\n",
    "    agent_executor = FoundryAgentExecutor(),\n",
    "    task_store = InMemoryTaskStore()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce89be",
   "metadata": {},
   "source": [
    "### Creating the A2A Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2a.server.apps import A2AStarletteApplication\n",
    "\n",
    "server = A2AStarletteApplication(\n",
    "    agent_card = public_agent_card,\n",
    "    http_handler = request_handler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f39869",
   "metadata": {},
   "source": [
    "### Starting the A2A Server\n",
    "\n",
    "Navigate to http://localhost:8080/.well-known/agent.json to see the agent public card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7fff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import uvicorn\n",
    "uvicorn.run(server.build(), host=\"0.0.0.0\", port=8080)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
